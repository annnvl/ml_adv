{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11b2f9510>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSeqUAS9JnTLgJalT/x8EiyQMZUXKpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118b7ee90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v2\")\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_states = T.matrix(\"states[batch,units]\")\n",
    "actions = T.ivector(\"action_ids[batch]\")\n",
    "rewards = T.vector(\"rewards[batch]\")\n",
    "next_states = T.matrix(\"next states[batch,units]\")\n",
    "is_end = T.ivector(\"vector[batch] where 1 means that session just ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "\n",
    "#input layer\n",
    "l_states = InputLayer((None,)+state_dim)\n",
    "\n",
    "nn = DenseLayer(l_states, 64, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "nn = DenseLayer(l_states, 128, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "#output layer\n",
    "l_qvalues = DenseLayer(nn ,num_units=n_actions,nonlinearity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_qvalues = get_output(l_qvalues,{l_states:current_states})\n",
    "predicted_next_qvalues = get_output(l_qvalues,{l_states:next_states})\n",
    "get_qvalues = theano.function([current_states], predicted_qvalues, allow_input_downcast=True)\n",
    "predicted_qvalues_for_actions = predicted_qvalues[T.arange(actions.shape[0]),actions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing target q-values under \n",
    "gamma = 0.99\n",
    "target_qvalues_for_actions = rewards + gamma * predicted_next_qvalues.max(axis=1)\n",
    "\n",
    "#zero-out q-values at the end\n",
    "target_qvalues_for_actions = (1-is_end)*target_qvalues_for_actions\n",
    "\n",
    "#don't compute gradient over target q-values (consider constant)\n",
    "target_qvalues_for_actions = theano.gradient.disconnected_grad(target_qvalues_for_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ((predicted_qvalues_for_actions - target_qvalues_for_actions) ** 2).mean()\n",
    "all_weights = get_all_params(l_qvalues,trainable=True)\n",
    "updates = lasagne.updates.sgd(loss,all_weights,learning_rate=1e-4)\n",
    "train_step = theano.function([current_states,actions,rewards,next_states,is_end],\n",
    "                             updates=updates, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.25 #initial epsilon\n",
    "\n",
    "def generate_session(t_max=1000):\n",
    "    \"\"\"play env with approximate q-learning agent and train it at the same time\"\"\"\n",
    "    \n",
    "    total_reward = 0\n",
    "    s = env.reset()\n",
    "    \n",
    "    for t in range(t_max):\n",
    "        \n",
    "        #get action q-values from the network\n",
    "        q_values = get_qvalues([s])[0] \n",
    "        \n",
    "        if np.random.random() < epsilon:\n",
    "            a = np.random.randint(0, n_actions)\n",
    "        else:\n",
    "            a = q_values.argmax()\n",
    "        \n",
    "        new_s,r,done,info = env.step(a)\n",
    "        \n",
    "        #train agent one step. Note that we use one-element arrays instead of scalars \n",
    "        #because that's what function accepts.\n",
    "        train_step([s],[a],[r],[new_s],[done])\n",
    "        \n",
    "        total_reward+=r\n",
    "        \n",
    "        s = new_s\n",
    "        if done: break\n",
    "            \n",
    "    return total_reward\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward:-244.464\tepsilon:0.23750\n",
      "mean reward:-254.642\tepsilon:0.22562\n",
      "mean reward:-219.737\tepsilon:0.21434\n",
      "mean reward:-194.038\tepsilon:0.20363\n",
      "mean reward:-190.739\tepsilon:0.19345\n",
      "mean reward:-153.970\tepsilon:0.18377\n",
      "mean reward:-197.223\tepsilon:0.17458\n",
      "mean reward:-190.319\tepsilon:0.16586\n",
      "mean reward:-130.627\tepsilon:0.15756\n",
      "mean reward:-95.373\tepsilon:0.14968\n",
      "mean reward:-93.495\tepsilon:0.14220\n",
      "mean reward:-64.186\tepsilon:0.13509\n",
      "mean reward:-65.599\tepsilon:0.12834\n",
      "mean reward:-80.879\tepsilon:0.12192\n",
      "mean reward:-70.018\tepsilon:0.11582\n",
      "mean reward:-43.228\tepsilon:0.11003\n",
      "mean reward:-12.959\tepsilon:0.10453\n",
      "mean reward:19.775\tepsilon:0.09930\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    \n",
    "    rewards = [generate_session() for _ in range(100)] #generate new sessions\n",
    "    \n",
    "    epsilon*=0.95\n",
    "    \n",
    "    print (\"mean reward:%.3f\\tepsilon:%.5f\"%(np.mean(rewards),epsilon))\n",
    "\n",
    "    if np.mean(rewards) > 300:\n",
    "        print (\"You Win!\")\n",
    "        break\n",
    "        \n",
    "    assert epsilon!=0, \"Please explore environment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
